{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image = tf.keras.preprocessing.image.load_img(\n",
    "    '/home/taityo1999/simple_bodypix_python/dance.jpg'\n",
    ")\n",
    "image_array = tf.keras.preprocessing.image.img_to_array(image)\n",
    "result = bodypix_model.predict_single(image_array)\n",
    "mask = result.get_mask(threshold=0.75)\n",
    "\n",
    "colored_mask = result.get_colored_part_mask(mask)\n",
    "tf.keras.preprocessing.image.save_img(\n",
    "    './output-colored-mask.jpg',\n",
    "    colored_mask\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tf_bodypix.api import download_model, load_model, BodyPixModelPaths\n",
    "import numpy as np\n",
    "\n",
    "bodypix_model = load_model(download_model(\n",
    "    BodyPixModelPaths.MOBILENET_FLOAT_50_STRIDE_16\n",
    "))\n",
    "\n",
    "\n",
    "# カメラ映像取得\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "\n",
    "# 変換処理ループ\n",
    "while True:\n",
    "    \n",
    "    # 初期フレームの読込\n",
    "    end_flag, c_frame = cap.read()\n",
    "    # 画像の取得と顔の検出\n",
    "\n",
    "    image = c_frame\n",
    "\n",
    "    image_array = tf.keras.preprocessing.image.img_to_array(image)\n",
    "    result = bodypix_model.predict_single(image_array)\n",
    "    mask = result.get_mask(threshold=0.75)\n",
    "\n",
    "    colored_mask = result.get_colored_part_mask(mask)\n",
    "    \n",
    "    colored_mask=np.array(colored_mask,dtype=np.uint8)\n",
    "    \n",
    "    \n",
    "    # BGRでの色抽出\n",
    "    bgrLower = np.array([135, 240, 87])     # 抽出する色の下限(BGR)\n",
    "    bgrUpper = np.array([175, 245, 91])   # 抽出する色の上限(BGR)\n",
    "    img_mask = cv2.inRange(colored_mask, bgrLower, bgrUpper) # BGRからマスクを作成\n",
    "    result = cv2.bitwise_and(image, image, mask=img_mask) # 元画像とマスクを合成\n",
    "\n",
    "\n",
    "    # フレーム表示\n",
    "    cv2.imshow(\"nomal\",c_frame)\n",
    "    cv2.imshow(\"color\",result)\n",
    "    \n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "\n",
    "# 終了処理\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "91 240 175\n",
    "87 245 135"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
